{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8ed903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "import torch\n",
    "from ultralytics.utils.files import increment_path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi.utils.yolov8 import download_yolov8s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62cf812",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = \"/mnt/ai-storage/jira/DIP555/raw_panos/AIC_2181/pano_sub/frames\"\n",
    "model_path = \"../sahi/models/20231231_yolov8x-albumentations.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_yolov8s_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check source path\n",
    "if not Path(image_source).is_dir():\n",
    "    raise NotADirectoryError(f\"Source path '{image_source}' is not a directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aacbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba952631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect objects from classes 0 and 32 only\n",
    "# classes = [0, 32]\n",
    "# model.overrides[\"classes\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model=model,\n",
    "    confidence_threshold=0.5,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output setup\n",
    "save_dir = increment_path(Path(image_source).parent / \"results_sahi\" / \"exp\", True)\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = list(Path(image_source).rglob(\"*.[jp][pn]g\"))\n",
    "\n",
    "if not image_files:\n",
    "    raise FileNotFoundError(f\"No image files found in: {image_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33539df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_detections = {}\n",
    "ball_detections = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = image_files[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bf172",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_sliced_prediction(\n",
    "    str(img_path),\n",
    "    detection_model,\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c753e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.export_visuals(export_dir=\"sahi_sample/\",\n",
    "                    text_size=5,\n",
    "                    rect_th=None,\n",
    "                    hide_labels=True,\n",
    "                    hide_conf=True,\n",
    "                    file_name=\"custom_yolov8_prediction_visual\",)\n",
    "# Image(\"sahi_sample/prediction_visual.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a08a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = cv2.imread(\"sahi_sample/custom_yolov8_prediction_visual.png\")\n",
    "visual = cv2.cvtColor(visual, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number = img_path.stem\n",
    "frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U imantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b88ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_frame_detections = {}\n",
    "ball_frame_detections = {}\n",
    "\n",
    "for bboxid, detection in enumerate(results.object_prediction_list):\n",
    "    if detection.category.name == 'player':\n",
    "        player_frame_detections[bboxid] = {\n",
    "                                            'bbox': [int(v) for v in detection.bbox.to_xyxy()],\n",
    "                                            'score': round(detection.score.value, 5)\n",
    "                                          }\n",
    "    else:\n",
    "        ball_frame_detections[bboxid] = {\n",
    "                                            'bbox': [int(v) for v in detection.bbox.to_xyxy()],\n",
    "                                            'score': round(detection.score.value, 5)\n",
    "                                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fabd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_detections[frame_number] = player_frame_detections\n",
    "ball_detections[frame_number] = ball_frame_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90627701",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    object_prediction_list = results.object_prediction_list\n",
    "    boxes_list = []\n",
    "    clss_list = []\n",
    "    for ind, _ in enumerate(object_prediction_list):\n",
    "        clss = object_prediction_list[ind].category.name\n",
    "        boxes = (\n",
    "            object_prediction_list[ind].bbox.minx,\n",
    "            object_prediction_list[ind].bbox.miny,\n",
    "            object_prediction_list[ind].bbox.maxx,\n",
    "            object_prediction_list[ind].bbox.maxy,\n",
    "        )\n",
    "\n",
    "        boxes_list.append(boxes)\n",
    "        clss_list.append(clss)\n",
    "\n",
    "    frame = cv2.imread(str(img_path))\n",
    "\n",
    "    # Create a copy of the original image to draw on\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    for box, cls in zip(boxes_list, clss_list):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(\n",
    "            frame_copy, (int(x1), int(y1)), (int(x2), int(y2)), (56, 56, 255), 2\n",
    "        )\n",
    "        label = str(cls)\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=0.6, thickness=1)[0]\n",
    "        cv2.rectangle(\n",
    "            frame_copy,\n",
    "            (int(x1), int(y1) - t_size[1] - 3),\n",
    "            (int(x1) + t_size[0], int(y1) + 3),\n",
    "            (56, 56, 255) if label == \"person\" else (56, 255, 56),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame_copy,\n",
    "            label,\n",
    "            (int(x1), int(y1) - 2),\n",
    "            0,\n",
    "            0.6,\n",
    "            [255, 255, 255] if label == \"person\" else [0, 0, 0],\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    frame_name = f\"{frame_number}_dets.jpg\"\n",
    "    frame_path = save_dir / frame_name\n",
    "    cv2.imwrite(\n",
    "        str(frame_path),\n",
    "        frame_copy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa16a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517de20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\n",
    "    \"players\": {},\n",
    "    \"ball\": {},\n",
    "    \"debug\": {\n",
    "        \"fps\": fps,\n",
    "        \"image_h\": height,\n",
    "        \"image_w\": width,\n",
    "        \"model_name\": args.model\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7616f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598c280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c05dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = {}\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = get_sliced_prediction(\n",
    "        str(img_path),\n",
    "        detection_model,\n",
    "        slice_height=512,\n",
    "        slice_width=512,\n",
    "        overlap_height_ratio=0.2,\n",
    "        overlap_width_ratio=0.2,\n",
    "    )\n",
    "\n",
    "    frame_number = int(img_path.stem)\n",
    "\n",
    "    object_prediction_list = [\n",
    "        res.to_coco_annotation().json for res in results.object_prediction_list\n",
    "    ]\n",
    "\n",
    "    detections[frame_number] = object_prediction_list\n",
    "\n",
    "    if debug:\n",
    "        object_prediction_list = results.object_prediction_list\n",
    "        boxes_list = []\n",
    "        clss_list = []\n",
    "        for ind, _ in enumerate(object_prediction_list):\n",
    "            clss = object_prediction_list[ind].category.name\n",
    "            boxes = (\n",
    "                object_prediction_list[ind].bbox.minx,\n",
    "                object_prediction_list[ind].bbox.miny,\n",
    "                object_prediction_list[ind].bbox.maxx,\n",
    "                object_prediction_list[ind].bbox.maxy,\n",
    "            )\n",
    "\n",
    "            boxes_list.append(boxes)\n",
    "            clss_list.append(clss)\n",
    "\n",
    "        frame = cv2.imread(str(img_path))\n",
    "\n",
    "        # Create a copy of the original image to draw on\n",
    "        frame_copy = frame.copy()\n",
    "\n",
    "        for box, cls in zip(boxes_list, clss_list):\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(\n",
    "                frame_copy, (int(x1), int(y1)), (int(x2), int(y2)), (56, 56, 255), 2\n",
    "            )\n",
    "            label = str(cls)\n",
    "            t_size = cv2.getTextSize(label, 0, fontScale=0.6, thickness=1)[0]\n",
    "            cv2.rectangle(\n",
    "                frame_copy,\n",
    "                (int(x1), int(y1) - t_size[1] - 3),\n",
    "                (int(x1) + t_size[0], int(y1) + 3),\n",
    "                (56, 56, 255) if label == \"person\" else (56, 255, 56),\n",
    "                -1,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame_copy,\n",
    "                label,\n",
    "                (int(x1), int(y1) - 2),\n",
    "                0,\n",
    "                0.6,\n",
    "                [255, 255, 255] if label == \"person\" else [0, 0, 0],\n",
    "                thickness=1,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        frame_name = f\"{frame_number:05d}_dets.jpg\"\n",
    "        frame_path = save_dir / frame_name\n",
    "        cv2.imwrite(\n",
    "            str(frame_path),\n",
    "            frame_copy,\n",
    "        )\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d81607",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    coco_out_path = f\"{save_dir}/coco_results.pkl\"\n",
    "    print(f\"Saving {coco_out_path}...\")\n",
    "    with open(coco_out_path, \"wb\") as f:\n",
    "        pickle.dump(detections, f)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Could not save {coco_out_path}\")\n",
    "\n",
    "print(\"Inference with SAHI is done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
