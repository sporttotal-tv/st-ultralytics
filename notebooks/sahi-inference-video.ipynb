{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e38199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/personal/pradip/st-ultralytics/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5182c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/personal/pradip/st-ultralytics'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c8ed903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import argparse\n",
    "import cv2\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "from ultralytics.utils.files import increment_path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from sahi.utils.yolov8 import download_yolov8s_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9230229d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw Data for this task is kept at /mnt/ai-storage/project/adidas/data/raw_4k/AIC_2182_P2/\n",
    "root_path = \"/mnt/ai-storage/jira/imtec356\"\n",
    "os.path.exists(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3b99b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clip = 'ma25fad386_5100_5160'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83cd39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/pano.mp4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = os.path.join(root_path, \n",
    "                                selected_clip,\n",
    "                               'pano.mp4')\n",
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b811e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "court_mask_path = '/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/pano_mask.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82cc369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total frames from pano video: 1498.0\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "print(f\"total frames from pano video: {cap.get(cv2.CAP_PROP_FRAME_COUNT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a62cf812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"scripts/models/20231231_yolov8x-albumentations.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9567d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_yolov8s_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2345dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check source video\n",
    "if not Path(video_path).is_file():\n",
    "    raise FileNotFoundError(f\"Source video at '{video_path}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "933bc0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model path\n",
    "if not Path(model_path).is_file():\n",
    "    # download_yolov8s_model(model_path)\n",
    "    raise FileNotFoundError(f\"Model path '{model_path}' is not a file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7510471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c26b847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output setup\n",
    "if out_dir is None:\n",
    "    out_dir = increment_path(Path(video_path).parent / \"detection_results\", exist_ok=True)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fda0aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e117594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results/debug_frames/1.jpg'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(Path(out_dir)/f\"debug_frames/{1}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "122aee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bebb31cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results/pano.bbox')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if out_path is None:\n",
    "    out_path = increment_path(Path(video_path).parent / \"detection_results\"/ (Path(video_path).stem+'.bbox'), exist_ok=True)\n",
    "else:\n",
    "    assert out_path.endswith(\".bbox\"), f\"out_path must end with .bbox, got {out_path}\"\n",
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90bf4420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results/pano.bbox.mp4'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(out_path)+'.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c8113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check court mask path\n",
    "use_court_mask = court_mask_path is not None\n",
    "if use_court_mask:\n",
    "    assert osp.exists(court_mask_path), f\"Cannot find court mask at {court_mask_path}\"\n",
    "    logger.info(f\"Use court mask: {court_mask_path}\")\n",
    "    court_mask = cv2.imread(court_mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66dd13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(court_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bc835",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba952631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect objects from classes 0 and 32 only\n",
    "# classes = [0, 32]\n",
    "# model.overrides[\"classes\"] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcdf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_model = AutoDetectionModel.from_pretrained(\n",
    "    model_type=\"yolov8\",\n",
    "    model=model,\n",
    "    confidence_threshold=0.5,\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output setup\n",
    "save_dir = increment_path(Path(image_source).parent / \"results_sahi\" / \"exp\", True)\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = list(Path(image_source).rglob(\"*.[jp][pn]g\"))\n",
    "\n",
    "if not image_files:\n",
    "    raise FileNotFoundError(f\"No image files found in: {image_source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33539df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_detections = {}\n",
    "ball_detections = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a1a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = image_files[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bf172",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_sliced_prediction(\n",
    "    str(img_path),\n",
    "    detection_model,\n",
    "    slice_height=512,\n",
    "    slice_width=512,\n",
    "    overlap_height_ratio=0.2,\n",
    "    overlap_width_ratio=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c753e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.export_visuals(export_dir=\"sahi_sample/\",\n",
    "                    text_size=5,\n",
    "                    rect_th=None,\n",
    "                    hide_labels=True,\n",
    "                    hide_conf=True,\n",
    "                    file_name=\"custom_yolov8_prediction_visual\",)\n",
    "# Image(\"sahi_sample/prediction_visual.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a08a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = cv2.imread(\"sahi_sample/custom_yolov8_prediction_visual.png\")\n",
    "visual = cv2.cvtColor(visual, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116516a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_number = img_path.stem\n",
    "frame_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U imantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b88ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_frame_detections = {}\n",
    "ball_frame_detections = {}\n",
    "\n",
    "for bboxid, detection in enumerate(results.object_prediction_list):\n",
    "    if detection.category.name == 'player':\n",
    "        player_frame_detections[bboxid] = {\n",
    "                                            'bbox': [int(v) for v in detection.bbox.to_xyxy()],\n",
    "                                            'score': round(detection.score.value, 5)\n",
    "                                          }\n",
    "    else:\n",
    "        ball_frame_detections[bboxid] = {\n",
    "                                            'bbox': [int(v) for v in detection.bbox.to_xyxy()],\n",
    "                                            'score': round(detection.score.value, 5)\n",
    "                                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fabd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_detections[frame_number] = player_frame_detections\n",
    "ball_detections[frame_number] = ball_frame_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90627701",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    object_prediction_list = results.object_prediction_list\n",
    "    boxes_list = []\n",
    "    clss_list = []\n",
    "    for ind, _ in enumerate(object_prediction_list):\n",
    "        clss = object_prediction_list[ind].category.name\n",
    "        boxes = (\n",
    "            object_prediction_list[ind].bbox.minx,\n",
    "            object_prediction_list[ind].bbox.miny,\n",
    "            object_prediction_list[ind].bbox.maxx,\n",
    "            object_prediction_list[ind].bbox.maxy,\n",
    "        )\n",
    "\n",
    "        boxes_list.append(boxes)\n",
    "        clss_list.append(clss)\n",
    "\n",
    "    frame = cv2.imread(str(img_path))\n",
    "\n",
    "    # Create a copy of the original image to draw on\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    for box, cls in zip(boxes_list, clss_list):\n",
    "        x1, y1, x2, y2 = box\n",
    "        cv2.rectangle(\n",
    "            frame_copy, (int(x1), int(y1)), (int(x2), int(y2)), (56, 56, 255), 2\n",
    "        )\n",
    "        label = str(cls)\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=0.6, thickness=1)[0]\n",
    "        cv2.rectangle(\n",
    "            frame_copy,\n",
    "            (int(x1), int(y1) - t_size[1] - 3),\n",
    "            (int(x1) + t_size[0], int(y1) + 3),\n",
    "            (56, 56, 255) if label == \"person\" else (56, 255, 56),\n",
    "            -1,\n",
    "        )\n",
    "        cv2.putText(\n",
    "            frame_copy,\n",
    "            label,\n",
    "            (int(x1), int(y1) - 2),\n",
    "            0,\n",
    "            0.6,\n",
    "            [255, 255, 255] if label == \"person\" else [0, 0, 0],\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    frame_name = f\"{frame_number}_dets.jpg\"\n",
    "    frame_path = save_dir / frame_name\n",
    "    cv2.imwrite(\n",
    "        str(frame_path),\n",
    "        frame_copy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa16a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517de20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = {\n",
    "    \"players\": {},\n",
    "    \"ball\": {},\n",
    "    \"debug\": {\n",
    "        \"fps\": fps,\n",
    "        \"image_h\": height,\n",
    "        \"image_w\": width,\n",
    "        \"model_name\": args.model\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7616f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598c280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c05dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = {}\n",
    "\n",
    "for img_path in image_files:\n",
    "    results = get_sliced_prediction(\n",
    "        str(img_path),\n",
    "        detection_model,\n",
    "        slice_height=512,\n",
    "        slice_width=512,\n",
    "        overlap_height_ratio=0.2,\n",
    "        overlap_width_ratio=0.2,\n",
    "    )\n",
    "\n",
    "    frame_number = int(img_path.stem)\n",
    "\n",
    "    object_prediction_list = [\n",
    "        res.to_coco_annotation().json for res in results.object_prediction_list\n",
    "    ]\n",
    "\n",
    "    detections[frame_number] = object_prediction_list\n",
    "\n",
    "    if debug:\n",
    "        object_prediction_list = results.object_prediction_list\n",
    "        boxes_list = []\n",
    "        clss_list = []\n",
    "        for ind, _ in enumerate(object_prediction_list):\n",
    "            clss = object_prediction_list[ind].category.name\n",
    "            boxes = (\n",
    "                object_prediction_list[ind].bbox.minx,\n",
    "                object_prediction_list[ind].bbox.miny,\n",
    "                object_prediction_list[ind].bbox.maxx,\n",
    "                object_prediction_list[ind].bbox.maxy,\n",
    "            )\n",
    "\n",
    "            boxes_list.append(boxes)\n",
    "            clss_list.append(clss)\n",
    "\n",
    "        frame = cv2.imread(str(img_path))\n",
    "\n",
    "        # Create a copy of the original image to draw on\n",
    "        frame_copy = frame.copy()\n",
    "\n",
    "        for box, cls in zip(boxes_list, clss_list):\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(\n",
    "                frame_copy, (int(x1), int(y1)), (int(x2), int(y2)), (56, 56, 255), 2\n",
    "            )\n",
    "            label = str(cls)\n",
    "            t_size = cv2.getTextSize(label, 0, fontScale=0.6, thickness=1)[0]\n",
    "            cv2.rectangle(\n",
    "                frame_copy,\n",
    "                (int(x1), int(y1) - t_size[1] - 3),\n",
    "                (int(x1) + t_size[0], int(y1) + 3),\n",
    "                (56, 56, 255) if label == \"person\" else (56, 255, 56),\n",
    "                -1,\n",
    "            )\n",
    "            cv2.putText(\n",
    "                frame_copy,\n",
    "                label,\n",
    "                (int(x1), int(y1) - 2),\n",
    "                0,\n",
    "                0.6,\n",
    "                [255, 255, 255] if label == \"person\" else [0, 0, 0],\n",
    "                thickness=1,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "        frame_name = f\"{frame_number:05d}_dets.jpg\"\n",
    "        frame_path = save_dir / frame_name\n",
    "        cv2.imwrite(\n",
    "            str(frame_path),\n",
    "            frame_copy,\n",
    "        )\n",
    "\n",
    "#     if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d81607",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    coco_out_path = f\"{save_dir}/coco_results.pkl\"\n",
    "    print(f\"Saving {coco_out_path}...\")\n",
    "    with open(coco_out_path, \"wb\") as f:\n",
    "        pickle.dump(detections, f)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Could not save {coco_out_path}\")\n",
    "\n",
    "print(\"Inference with SAHI is done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a739402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e2aa10e",
   "metadata": {},
   "source": [
    "# Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf0aa2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/ai-storage/personal/pradip/st-ultralytics'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "445bc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inference_sahi import detect_bboxes_from_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "362b4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'scripts/models/20231231_yolov8x-albumentations.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b9dc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = '/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/pano.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e0635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "court_mask_path = '/mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/pano_mask.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac43552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-03-13 09:07:43.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscripts.inference_sahi\u001b[0m:\u001b[36mdetect_bboxes_from_video\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1mout_dir is: /mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results\u001b[0m\n",
      "\u001b[32m2024-03-13 09:07:43.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscripts.inference_sahi\u001b[0m:\u001b[36mdetect_bboxes_from_video\u001b[0m:\u001b[36m166\u001b[0m - \u001b[1mout_path is: /mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/detection_results/pano.bbox\u001b[0m\n",
      "\u001b[32m2024-03-13 09:07:43.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mscripts.inference_sahi\u001b[0m:\u001b[36mdetect_bboxes_from_video\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mUse court mask: /mnt/ai-storage/jira/imtec356/ma25fad386_5100_5160/pano_mask.png\u001b[0m\n",
      "Player Detection for pano - 0  to 10: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbosity 1 True\n",
      "Performing prediction on 20 number of slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Player Detection for pano - 0  to 10: 0it [00:07, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualisation\n",
      "Dumping final image to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdetect_bboxes_from_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myolov8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcourt_mask_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcourt_mask_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mconfidence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ai-storage/personal/pradip/st-ultralytics/scripts/inference_sahi.py:233\u001b[0m, in \u001b[0;36mdetect_bboxes_from_video\u001b[0;34m(video_path, model_path, model_type, start_time, end_time, out_dir, out_path, court_mask_path, confidence_threshold, device, verbosity, debug, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m video_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m         video_out_path \u001b[38;5;241m=\u001b[39m \u001b[43mout_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    234\u001b[0m         fourcc \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmp4v\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m         video_writer \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(video_out_path, fourcc, video\u001b[38;5;241m.\u001b[39mframe_rate, (video\u001b[38;5;241m.\u001b[39mimage_w, video\u001b[38;5;241m.\u001b[39mimage_h))\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "source": [
    "detect_bboxes_from_video(video_path = video_path,\n",
    "                         model_path = model_path,\n",
    "                         model_type = \"yolov8\",\n",
    "                         start_time = 0,\n",
    "                         end_time = 10,\n",
    "                         court_mask_path = court_mask_path,\n",
    "                         confidence_threshold= 0.5,\n",
    "                         verbosity = 1,\n",
    "                         debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76c770ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout_path\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_path' is not defined"
     ]
    }
   ],
   "source": [
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3d654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
